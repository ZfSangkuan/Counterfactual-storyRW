{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import gc\n",
    "import bisect\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from aser.database.base import SqliteDBConnection, MongoDBConnection\n",
    "from aser.database.kg_connection import CHUNKSIZE\n",
    "from aser.database.kg_connection import EVENTUALITY_TABLE_NAME, EVENTUALITY_COLUMNS, EVENTUALITY_COLUMN_TYPES\n",
    "from aser.database.kg_connection import RELATION_TABLE_NAME, RELATION_COLUMNS, RELATION_COLUMN_TYPES\n",
    "from aser.concept.concept_extractor import ASERConceptExtractor\n",
    "from aser.concept.concept_connection import ASERConceptConnection\n",
    "from aser.concept.concept_connection import CONCEPT_TABLE_NAME, CONCEPT_COLUMNS, CONCEPT_COLUMN_TYPES\n",
    "from aser.concept.concept_connection import CONCEPTINSTANCEPAIR_TABLE_NAME, CONCEPTINSTANCEPAIR_COLUMNS, CONCEPTINSTANCEPAIR_COLUMN_TYPES\n",
    "from aser.extract.aser_extractor import DiscourseASERExtractor\n",
    "from aser.eventuality import Eventuality\n",
    "from aser.relation import Relation, relation_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row_to_eventuality(row):\n",
    "    eventuality = Eventuality().decode(row[\"info\"])\n",
    "    eventuality.eid = row[\"_id\"]\n",
    "    eventuality.frequency = row[\"frequency\"]\n",
    "    eventuality.pattern = row[\"pattern\"]\n",
    "    return eventuality\n",
    "\n",
    "def convert_row_to_relation(row):\n",
    "    return Relation(row[\"hid\"], row[\"tid\"], {r: cnt for r, cnt in row.items() if isinstance(cnt, float) and cnt > 0.0})\n",
    "\n",
    "def build_concept_instance_table_from_aser_kg(aser_conceptualizer, erows):\n",
    "    cid2concept = dict()\n",
    "    concept_instance_pairs = []\n",
    "    cid_to_filter_score = dict()\n",
    "    for erow in tqdm(erows):\n",
    "        event = convert_row_to_eventuality(erow)\n",
    "        results = aser_conceptualizer.conceptualize(event)\n",
    "        for concept, score in results:\n",
    "            if concept.cid not in cid2concept:\n",
    "                cid2concept[concept.cid] = copy.copy(concept)\n",
    "            concept = cid2concept[concept.cid]\n",
    "            if (event.eid, event.pattern, score) not in concept.instances:\n",
    "                concept.instances.append(((event.eid, event.pattern, score)))\n",
    "                if concept.cid not in cid_to_filter_score:\n",
    "                    cid_to_filter_score[concept.cid] = 0.0\n",
    "                cid_to_filter_score[concept.cid] += score * event.frequency\n",
    "            concept_instance_pairs.append((concept, event, score))\n",
    "    return cid2concept, concept_instance_pairs, cid_to_filter_score\n",
    "\n",
    "def build_concept_relation_table_from_aser_kg(aser_concept_conn, rrows):\n",
    "    rid2relation = dict()\n",
    "    hid2related_events = defaultdict(list)\n",
    "    for rrow in rrows:\n",
    "        relation = convert_row_to_relation(rrow)\n",
    "        hid2related_events[rrow[\"hid\"]].append((rrow[\"tid\"], relation))\n",
    "        \n",
    "    for h_cid in tqdm(aser_concept_conn.cids):\n",
    "        instances = aser_concept_conn.get_eventualities_given_concept(h_cid)\n",
    "        for h_eid, pattern, instance_score in instances:\n",
    "            # eid -> event -> related eids -> related events, relations -> related concepts, relations\n",
    "            related_events = hid2related_events[h_eid]\n",
    "            for t_eid, relation in related_events:\n",
    "                concept_score_pairs = aser_concept_conn.get_concepts_given_eventuality(t_eid)\n",
    "                for t_concept, score in concept_score_pairs:\n",
    "                    t_cid = t_concept.cid\n",
    "                    if h_cid == t_cid:\n",
    "                        continue\n",
    "                    rid = Relation.generate_rid(h_cid, t_cid)\n",
    "                    if rid not in rid2relation:\n",
    "                        rid2relation[rid] = Relation(h_cid, t_cid)\n",
    "                    rid2relation[rid].update(\n",
    "                        {k: v * instance_score * score for k, v in relation.relations.items()})\n",
    "    return rid2relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_path = \"/home/xliucr/ASER/database/core_2.0/all/KG.db\"\n",
    "\n",
    "kg_conn = SqliteDBConnection(kg_path, CHUNKSIZE)\n",
    "eid2eventuality = dict()\n",
    "rid2relation = dict()\n",
    "\n",
    "for erow in kg_conn.get_columns(EVENTUALITY_TABLE_NAME, EVENTUALITY_COLUMNS):\n",
    "    eventuality = convert_row_to_eventuality(erow)\n",
    "    eid2eventuality[eventuality.eid] = eventuality\n",
    "    \n",
    "for rrow in kg_conn.get_columns(RELATION_TABLE_NAME, RELATION_COLUMNS):\n",
    "    relation = convert_row_to_relation(rrow)\n",
    "    rid2relation[relation.rid] = relation\n",
    "\n",
    "kg_conn.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/home/xliucr/ASER/database/core_2.0/all/rid2sids.pkl\", \"rb\") as f:\n",
    "    rid2sids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xliucr/miniconda3/envs/ASER/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/xliucr/miniconda3/envs/ASER/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "aser_extractor = DiscourseASERExtractor(corenlp_path=\"x\", corenlp_port=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[probase-concept] Loading Probase files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 79/33377320 [00:01<134:37:51, 68.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[probase-concept] Building index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33377320/33377320 [02:02<00:00, 272556.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[probase-concept] Loading data finished in 138.20 s\n"
     ]
    }
   ],
   "source": [
    "aser_conceptualizer = ASERConceptExtractor(\n",
    "    method=\"probase\",\n",
    "    # probase_path=\"/data/hjpan/probase/data-concept-instance-relations-yq.txt\",\n",
    "    # probase_path=r\"D:\\Data\\probase\\data-concept-instance-relations-yq.txt\",\n",
    "    probase_path=\"/home/data/corpora/probase/data-concept-instance-relations-demo.txt\",\n",
    "    probase_topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = aser_extractor.extract_from_text(\"PERSON feel hungry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0][0][0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0][0][0].skeleton_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = aser_extractor.extract_from_text(\"PERSON eat food.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0][0][0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_list = list()\n",
    "feel_hungry_list = list()\n",
    "eat_food_list = list()\n",
    "have_breakfast_list = list()\n",
    "have_lunch_list = list()\n",
    "have_dinner_list = list()\n",
    "\n",
    "for eid, e in tqdm(eid2eventuality.items()):\n",
    "    if e.pattern != \"s-be-a\" and e.pattern != \"s-v-a\" and e.pattern != \"s-v-o\":\n",
    "        continue\n",
    "    skeleton_words = e.skeleton_words\n",
    "    if e.pattern == \"s-be-a\" and skeleton_words[-2] == \"be\" and skeleton_words[-1] == \"hungry\":\n",
    "        be_hungry_list.append(eid)\n",
    "    if e.pattern == \"s-v-a\" and skeleton_words[-2] == \"feel\" and skeleton_words[-1] == \"hungry\":\n",
    "        feel_hungry_list.append(eid)\n",
    "    if e.pattern == \"s-v-o\" and skeleton_words[-2] == \"eat\" and skeleton_words[-1] == \"food\":\n",
    "        eat_food_list.append(eid)\n",
    "    if e.pattern == \"s-v-o\" and skeleton_words[-2] == \"have\":\n",
    "        if skeleton_words[-1] == \"breakfast\":\n",
    "            have_breakfast_list.append(eid)\n",
    "        elif skeleton_words[-1] == \"lunch\":\n",
    "            have_lunch_list.append(eid)\n",
    "        elif skeleton_words[-1] == \"dinner\":\n",
    "            have_dinner_list.append(eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(be_hungry_list), len(feel_hungry_list), len(eat_food_list), len(have_breakfast_list), len(have_lunch_list), len(have_dinner_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_to_eat_food = Relation(\n",
    "    aser_extractor.extract_from_text(\"PERSON be hungry.\")[0][0][0].eid,\n",
    "    aser_extractor.extract_from_text(\"PERSON eat food.\")[0][0][0].eid\n",
    ")\n",
    "\n",
    "be_hungry_to_have_breakfast = Relation(\n",
    "    aser_extractor.extract_from_text(\"PERSON be hungry.\")[0][0][0].eid,\n",
    "    aser_extractor.extract_from_text(\"PERSON have breakfast.\")[0][0][0].eid\n",
    ")\n",
    "\n",
    "be_hungry_to_have_lunch = Relation(\n",
    "    aser_extractor.extract_from_text(\"PERSON be hungry.\")[0][0][0].eid,\n",
    "    aser_extractor.extract_from_text(\"PERSON have lunch.\")[0][0][0].eid\n",
    ")\n",
    "\n",
    "be_hungry_to_have_dinner = Relation(\n",
    "    aser_extractor.extract_from_text(\"PERSON be hungry.\")[0][0][0].eid,\n",
    "    aser_extractor.extract_from_text(\"PERSON have dinner.\")[0][0][0].eid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e1 in tqdm(be_hungry_list):\n",
    "    for e2 in eat_food_list:\n",
    "        rid = Relation.generate_rid(e1, e2)\n",
    "        r = rid2relation.get(rid, None)\n",
    "        if r:\n",
    "            be_hungry_to_eat_food.update(r.relations)\n",
    "    for e2 in have_breakfast_list:\n",
    "        rid = Relation.generate_rid(e1, e2)\n",
    "        r = rid2relation.get(rid, None)\n",
    "        if r:\n",
    "            be_hungry_to_have_breakfast.update(r.relations)\n",
    "    for e2 in have_lunch_list:\n",
    "        rid = Relation.generate_rid(e1, e2)\n",
    "        r = rid2relation.get(rid, None)\n",
    "        if r:\n",
    "            be_hungry_to_have_lunch.update(r.relations)\n",
    "    for e2 in have_dinner_list:\n",
    "        rid = Relation.generate_rid(e1, e2)\n",
    "        r = rid2relation.get(rid, None)\n",
    "        if r:\n",
    "            be_hungry_to_have_dinner.update(r.relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_to_eat_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_to_have_breakfast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_to_have_lunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_hungry_to_have_dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_food_to_be_hungry = Relation(\n",
    "    aser_extractor.extract_from_text(\"PERSON eat food.\")[0][0][0].eid,\n",
    "    aser_extractor.extract_from_text(\"PERSON be hungry.\")[0][0][0].eid\n",
    ")\n",
    "print(eat_food_to_be_hungry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e1 in be_hungry_list:\n",
    "    for e2 in eat_food_list:\n",
    "        rid = Relation.generate_rid(e1, e2)\n",
    "        r = rid2relation.get(rid, None)\n",
    "        if r:\n",
    "            print(rid, r)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid2sids[\"54e31deec8120df8a64a11f7c6b734179a45b828\"], rid2relation[\"54e31deec8120df8a64a11f7c6b734179a45b828\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid2sids[\"e16aaaf2d465d4dbcb24fd446c4b384d16a029f5\"], rid2relation[\"e16aaaf2d465d4dbcb24fd446c4b384d16a029f5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid2sids[\"4a213852913f255a88efbe9844a6e969efc8d367\"], rid2relation[\"4a213852913f255a88efbe9844a6e969efc8d367\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid2sids[\"106766755d0d3c301b02ee4db9961b8f524f23d7\"], rid2relation[\"106766755d0d3c301b02ee4db9961b8f524f23d7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_relation(text1, text2, exact_match=True):\n",
    "    e1 = aser_extractor.extract_eventualities_from_text(text1)[0][0]\n",
    "    e2 = aser_extractor.extract_eventualities_from_text(text2)[0][0]\n",
    "    if exact_match:\n",
    "        return rid2relation[Relation.generate_rid(e1.eid, e2.eid)]\n",
    "    else:\n",
    "        relation = Relation(e1.eid, e2.eid)\n",
    "        for rid, r in rid2relation.items():\n",
    "            if r.hid == e1.eid:\n",
    "                tail = eid2eventuality[r.tid]\n",
    "                if tail.pattern == e2.pattern and tail.skeleton_words == e2.skeleton_words:\n",
    "                    relation.update(r.relations)\n",
    "            if r.tid == e2.eid:\n",
    "                head = eid2eventuality[r.hid]\n",
    "                if head.pattern == e1.pattern and head.skeleton_words == e1.skeleton_words:\n",
    "                    relation.update(r.relations)\n",
    "        return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_relation(\"I sleep\", \"I am tired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_relation(\"I sleep\", \"I am tired\", exact_match=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_relation(\"I want to sleep\", \"I am tired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_relation(\"I want to sleep\", \"I am tired\", exact_match=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1 = aser_extractor.extract_from_text(\"I am hungry.\")[0][0][0]\n",
    "# e2 = aser_extractor.extract_from_text(\"I am thirsty.\")[0][0][0]\n",
    "# e3 = aser_extractor.extract_from_text(\"I am full.\")[0][0][0]\n",
    "# e4 = aser_extractor.extract_from_text(\"He orders beef\")[0][0][0]\n",
    "e5 = aser_extractor.extract_from_text(\"He gives me beef\")[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = aser_conceptualizer.conceptualize(e1)[0][0]\n",
    "# c2 = aser_conceptualizer.conceptualize(e2)[0][0]\n",
    "# c3 = aser_conceptualizer.conceptualize(e3)[0][0]\n",
    "# c4 = aser_conceptualizer.conceptualize(e4)[0][0]\n",
    "c5 = aser_conceptualizer.conceptualize(e5)[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_kg_path = \"/home/data/corpora/aser/concept/0.3/5/concept.db\"\n",
    "concept_conn = SqliteDBConnection(concept_kg_path, CHUNKSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_e1 = json.loads(list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(CONCEPT_COLUMNS), CONCEPT_TABLE_NAME, c1.cid)))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_e2 = json.loads(list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(CONCEPT_COLUMNS), CONCEPT_TABLE_NAME, c2.cid)))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_e3 = json.loads(list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(CONCEPT_COLUMNS), CONCEPT_TABLE_NAME, c3.cid)))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_e4 = json.loads(list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(CONCEPT_COLUMNS), CONCEPT_TABLE_NAME, c4.cid)))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5_e5 = json.loads(list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(CONCEPT_COLUMNS), CONCEPT_TABLE_NAME, c5.cid)))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.70513914380411"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([e[2] for e in c4_e4[\"instances\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_id', 'c0448909c96a4fce90c6d30ce034376db5d45683'),\n",
       " ('hid', '7669465a3de773b48e3869b597f21275bc9cb4ee'),\n",
       " ('tid', '1887f3678c49b6ea75c70dec6e5f0e91ac722d5e'),\n",
       " ('Precedence', 0.0),\n",
       " ('Succession', 0.0),\n",
       " ('Synchronous', 0.0),\n",
       " ('Reason', 0.0),\n",
       " ('Result', 0.07749597423510467),\n",
       " ('Condition', 0.0),\n",
       " ('Contrast', 0.0),\n",
       " ('Concession', 0.0),\n",
       " ('Conjunction', 0.05319645356976201),\n",
       " ('Instantiation', 0.0),\n",
       " ('Restatement', 0.0),\n",
       " ('ChosenAlternative', 0.0),\n",
       " ('Alternative', 0.0),\n",
       " ('Exception', 0.0),\n",
       " ('Co_Occurrence', 0.19096707443217031)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(RELATION_COLUMNS, list(concept_conn._conn.execute(\"SELECT %s FROM %s WHERE _id == \\\"%s\\\"; \" % (\",\".join(RELATION_COLUMNS), RELATION_TABLE_NAME, Relation.generate_rid(c1.cid, c4.cid))))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i be hungry (1.000) Result (0.125) i order orange chicken (0.069)\n",
      "i be not too hungry (1.000) Result (1.000) i order the fried chicken (0.069)\n"
     ]
    }
   ],
   "source": [
    "for x in c1_e1[\"instances\"]:\n",
    "    for y in c4_e4[\"instances\"]:\n",
    "        z = Relation.generate_rid(x[0], y[0])\n",
    "        z = rid2relation.get(z, None)\n",
    "        if z is None:\n",
    "            continue\n",
    "        z = z.relations.get(\"Result\", 0.0)\n",
    "        if z == 0.0:\n",
    "            continue\n",
    "        print(\" \".join(eid2eventuality[x[0]].words), \"(%.3f)\" % (x[2]),  \"Result (%.3f)\" % (z), \" \".join(eid2eventuality[y[0]].words), \"(%.3f)\" % (y[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5fe81d2719c163f4ddf33d2ac133d47e27a0adaf', 's-v-o', 0.06888531043120415]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__PERSON__0 give __PERSON__1 red-meat"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
